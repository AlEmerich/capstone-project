@article{1993-TrunkMotion,
author = "Yamaguchi, J.-I and TAKANISHI, Atsuo and KATO, Ichiro",
year = "1993",
month = "08",
pages = "561 - 566 vol.1",
title = "Development of a Biped Walking Robot Compensating for Three-Axis Moment by Trunk Motion.",
volume = "11",
isbn = "0-7803-0823-9",
booktitle = "JRSJ",
journal = "1993 IEEE/RSJ International Conference"
}

@article{1999-KHR-2,
author = "Nagasaka, Ken'ichiro and Inoue, Hirochika and Inaba, Masayuki",
year = "1999",
month = "02",
pages = "908 - 913 vol.6",
title = "Dynamic walking pattern generation for a humanoid robot based on optimal gradient method",
volume = "6",
journal = "1999 IEEE International Conference"
}

@article{2013-TOG-MuscleBasedBipeds,
  title = "Flexible Muscle-Based Locomotion for Bipedal Creatures",
  author = "Thomas Geijtenbeek and Michiel van de Panne and A. Frank van der Stappen",
  journal = "ACM Transactions on Graphics",
  year = "2013",
  volume = "32",
  number = "6",
  publisher = "ACM SIGGRAPH"
}

@misc{1606.01540,
  Author = "Greg Brockman and Vicki Cheung and Ludwig Pettersson and Jonas Schneider and John Schulman and Jie Tang and Wojciech Zaremba",
  Title = "OpenAI Gym",
  Year = "2016",
  Eprint = "arXiv:1606.01540",
}

@article{silver2017mastering,
  added-at = "2017-12-15T02:14:58.000+0100",
  author = "Silver, David and Schrittwieser, Julian and Simonyan, Karen and Antonoglou, Ioannis and Huang, Aja and Guez, Arthur and Hubert, Thomas and Baker, Lucas and Lai, Matthew and Bolton, Adrian and Chen, Yutian and Lillicrap, Timothy and Hui, Fan and Sifre, Laurent and van den Driessche, George and Graepel, Thore and Hassabis, Demis",
  biburl = "https://www.bibsonomy.org/bibtex/2ecdfbfcceb55ee5f14c1c375ad71f2cb/achakraborty",
  description = "Mastering the game of Go without human knowledge | Nature",
  interhash = "c45d318e105d0f2d62ccc28c2699d9d4",
  intrahash = "ecdfbfcceb55ee5f14c1c375ad71f2cb",
  journal = "Nature",
  keywords = "2017 deep-learning deepmind google paper reinforcement-learning",
  month = oct,
  pages = "354--",
  publisher = "Macmillan Publishers Limited, part of Springer Nature. All rights reserved.",
  timestamp = "2017-12-15T02:14:58.000+0100",
  title = "Mastering the game of Go without human knowledge",
  url = "http://dx.doi.org/10.1038/nature24270",
  volume = 550,
  year = 2017
}

@incollection{kidzinski2018learningtorun,
  author      = "Kidzi\'nski, {\L}ukasz and Mohanty, Sharada P and Ong, Carmichael and Hicks, Jennifer and Francis, Sean and Levine, Sergey and Salath\'e, Marcel and Delp, Scott",
  title       = "Learning to Run challenge: Synthesizing physiologically accurate motion using deep reinforcement learning",
  editor      = "Escalera, Sergio and Weimer, Markus",
  booktitle   = "NIPS 2017 Competition Book",
  publisher   = "Springer",
  address     = "Springer",
  year        = 2018
}

@article{doi:10.1002/rob.21559,
author = "Siyuan Feng and Eric Whitman and X. Xinjilefu and Christopher G. Atkeson",
title = "Optimizationâbased Full Body Control for the DARPA Robotics Challenge",
journal = "Journal of Field Robotics",
volume = "32",
number = "2",
pages = "293-312",
doi = "10.1002/rob.21559",
url = "https://onlinelibrary.wiley.com/doi/abs/10.1002/rob.21559",
eprint = "https://onlinelibrary.wiley.com/doi/pdf/10.1002/rob.21559",
abstract = "We describe our full body humanoid control approach developed for the simulation phase of the DARPA Robotics Challenge (DRC), as well as the modifications made for the DARPA Robotics Challenge Trials. We worked with the Boston Dynamics Atlas robot. Our approach was initially targeted at walking, and it consisted of two levels of optimization: a highâlevel trajectory optimizer that reasons about center of mass and swing foot trajectories, and a lowâlevel controller that tracks those trajectories by solving floating base full body inverse dynamics using quadratic programming. This controller is capable of walking on rough terrain, and it also achieves long footsteps, fast walking speeds, and heelâstrike and toeâoff in simulation. During development of these and other whole body tasks on the physical robot, we introduced an additional optimization component in the lowâlevel controller, namely an inverse kinematics controller. Modeling and torque measurement errors and hardware features of the Atlas robot led us to this threeâpart approach, which was applied to three tasks in the DRC Trials in December 2013."
}