\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\providecommand\@newglossary[4]{}
\@newglossary{main}{glg}{gls}{glo}
\providecommand \oddpage@label [2]{}
\select@language{english}
\@writefile{toc}{\select@language{english}}
\@writefile{lof}{\select@language{english}}
\@writefile{lot}{\select@language{english}}
\citation{1606.01540}
\citation{journals/corr/LillicrapHPHETS15}
\@writefile{toc}{\contentsline {section}{\numberline {1}Definition of the problem}{2}{section.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1}Project Overview}{2}{subsection.1.1}}
\@writefile{toc}{\contentsline {paragraph}{}{2}{section*.1}}
\@writefile{toc}{\contentsline {paragraph}{}{2}{section*.2}}
\@writefile{toc}{\contentsline {paragraph}{}{2}{section*.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2}Problem Statement}{2}{subsection.1.2}}
\@writefile{toc}{\contentsline {paragraph}{}{2}{section*.4}}
\@writefile{toc}{\contentsline {paragraph}{Actor Critic algorithm}{3}{section*.5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3}Metrics}{3}{subsection.1.3}}
\@writefile{toc}{\contentsline {paragraph}{}{3}{section*.6}}
\@writefile{toc}{\contentsline {paragraph}{}{3}{section*.7}}
\@writefile{toc}{\contentsline {section}{\numberline {2}Analysis}{4}{section.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Data Exploration: RoboschoolHumanoid-v1}{4}{subsection.2.1}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.1}Observation space}{4}{subsubsection.2.1.1}}
\newlabel{subsubsec:obs_space}{{2.1.1}{4}{Observation space}{subsubsection.2.1.1}{}}
\@writefile{toc}{\contentsline {paragraph}{Definition}{4}{section*.8}}
\@writefile{toc}{\contentsline {paragraph}{}{4}{section*.9}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.2}Action space}{4}{subsubsection.2.1.2}}
\@writefile{toc}{\contentsline {paragraph}{Definition}{4}{section*.10}}
\@writefile{toc}{\contentsline {paragraph}{}{4}{section*.11}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.3}Reward}{5}{subsubsection.2.1.3}}
\@writefile{toc}{\contentsline {paragraph}{Definition}{5}{section*.12}}
\@writefile{toc}{\contentsline {paragraph}{}{5}{section*.13}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Roboschool environment\relax }}{6}{figure.caption.14}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:exploratory}{{1}{6}{Roboschool environment\relax }{figure.caption.14}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Exploratory Visualization}{6}{subsection.2.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Algorithm and Techniques}{6}{subsection.2.3}}
\@writefile{toc}{\contentsline {paragraph}{Deep Deterministic Policy Gradient}{6}{section*.15}}
\citation{journals/corr/LillicrapHPHETS15}
\citation{journals/corr/LillicrapHPHETS15}
\citation{journals/corr/LillicrapHPHETS15}
\citation{GuLilGhaTurLev17}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces First, the environment gives the first state to the actor and it chose the action following the policy. The action is given back to the environment and a reward is computed, meaning how good the action was for that state, and sent to the critic network. The critic computes the $Q$ value of that action by minimizing the loss and gives the error to the actor in order to let him train on it.\relax }}{7}{figure.caption.16}}
\newlabel{fig:actor-critic}{{2}{7}{First, the environment gives the first state to the actor and it chose the action following the policy. The action is given back to the environment and a reward is computed, meaning how good the action was for that state, and sent to the critic network. The critic computes the $Q$ value of that action by minimizing the loss and gives the error to the actor in order to let him train on it.\relax }{figure.caption.16}{}}
\@writefile{toc}{\contentsline {paragraph}{}{7}{section*.17}}
\@writefile{toc}{\contentsline {paragraph}{}{7}{section*.18}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4}Benchmark}{7}{subsection.2.4}}
\@writefile{toc}{\contentsline {paragraph}{}{7}{section*.21}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Algorithm from \citeauthor  {journals/corr/LillicrapHPHETS15} paper\relax }}{8}{figure.caption.19}}
\newlabel{fig:algoDDPG}{{3}{8}{Algorithm from \citeauthor {journals/corr/LillicrapHPHETS15} paper\relax }{figure.caption.19}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Methodology}{8}{section.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Data Preprocessing}{8}{subsection.3.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Random Policy\relax }}{9}{figure.caption.20}}
\newlabel{fig:randompolicy}{{4}{9}{Random Policy\relax }{figure.caption.20}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Average return over episodes in HalfCheetah-v1 and Humanoid-v1 during learning, comparing Q-Prop against other model-free algorithms. Q-Prop with vanilla policy gradient outperforms TRPO on HalfCheetah. Q-Prop significantly outperforms TRPO in convergence time on Humanoid.\relax }}{9}{figure.caption.22}}
\newlabel{fig:benchmark}{{5}{9}{Average return over episodes in HalfCheetah-v1 and Humanoid-v1 during learning, comparing Q-Prop against other model-free algorithms. Q-Prop with vanilla policy gradient outperforms TRPO on HalfCheetah. Q-Prop significantly outperforms TRPO in convergence time on Humanoid.\relax }{figure.caption.22}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Implementation}{9}{subsection.3.2}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.1}Project Structure}{9}{subsubsection.3.2.1}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.2}Replay buffer}{10}{subsubsection.3.2.2}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.3}Neural networks: Actor and Critic}{10}{subsubsection.3.2.3}}
\@writefile{toc}{\contentsline {paragraph}{Keras vs Tensorflow}{10}{section*.23}}
\@writefile{toc}{\contentsline {paragraph}{The Actor}{10}{section*.24}}
\@writefile{toc}{\contentsline {paragraph}{The Critic}{11}{section*.25}}
\@writefile{toc}{\contentsline {paragraph}{Target networks}{11}{section*.26}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.4}Training}{11}{subsubsection.3.2.4}}
\@writefile{toc}{\contentsline {paragraph}{The Actor}{11}{section*.27}}
\@writefile{toc}{\contentsline {paragraph}{The Critic}{11}{section*.28}}
\@writefile{toc}{\contentsline {paragraph}{Process}{12}{section*.29}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.5}Noise}{13}{subsubsection.3.2.5}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.6}The Agent}{13}{subsubsection.3.2.6}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.7}Hyper Parameters}{14}{subsubsection.3.2.7}}
\newlabel{subsubsec:hp_params}{{3.2.7}{14}{Hyper Parameters}{subsubsection.3.2.7}{}}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Hyper parameters description and definition for training purpose\relax }}{14}{table.caption.30}}
\newlabel{tab:hyperparams}{{1}{14}{Hyper parameters description and definition for training purpose\relax }{table.caption.30}{}}
\citation{journals/corr/LillicrapHPHETS15}
\citation{DBLP:journals/corr/abs-1801-10425}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Refinement}{15}{subsection.3.3}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.3.1}Noise}{15}{subsubsection.3.3.1}}
\newlabel{fig:noise_600}{{6a}{15}{Training with noise every steps until the epoch 600\relax }{figure.caption.31}{}}
\newlabel{sub@fig:noise_600}{{a}{15}{Training with noise every steps until the epoch 600\relax }{figure.caption.31}{}}
\newlabel{fig:noise_350}{{6b}{15}{Training with noise every steps until the epoch 350\relax }{figure.caption.31}{}}
\newlabel{sub@fig:noise_350}{{b}{15}{Training with noise every steps until the epoch 350\relax }{figure.caption.31}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Affect of the noise on the training process.\relax }}{15}{figure.caption.31}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.3.2}Network definition}{15}{subsubsection.3.3.2}}
\citation{journals/corr/LillicrapHPHETS15}
\@writefile{toc}{\contentsline {section}{\numberline {4}Results}{16}{section.4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Model Evaluation and Validation}{16}{subsection.4.1}}
\@writefile{toc}{\contentsline {paragraph}{}{16}{section*.32}}
\newlabel{fig:criticlossmountain}{{7a}{16}{Critic loss\relax }{figure.caption.33}{}}
\newlabel{sub@fig:criticlossmountain}{{a}{16}{Critic loss\relax }{figure.caption.33}{}}
\newlabel{fig:avgrewardmountain}{{7b}{16}{Average reward\relax }{figure.caption.33}{}}
\newlabel{sub@fig:avgrewardmountain}{{b}{16}{Average reward\relax }{figure.caption.33}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Training of MountainCarContinuous environments\relax }}{16}{figure.caption.33}}
\newlabel{fig:mountaincartrain}{{7}{16}{Training of MountainCarContinuous environments\relax }{figure.caption.33}{}}
\@writefile{toc}{\contentsline {paragraph}{}{16}{section*.34}}
\@writefile{toc}{\contentsline {paragraph}{}{16}{section*.35}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces Soft target update operations graph\relax }}{17}{figure.caption.36}}
\newlabel{fig:softtargetgraph}{{8}{17}{Soft target update operations graph\relax }{figure.caption.36}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Justification}{17}{subsection.4.2}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Conclusion}{17}{section.5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}Free-Form Visualization}{17}{subsection.5.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2}Reflection}{17}{subsection.5.2}}
\@writefile{toc}{\contentsline {paragraph}{}{17}{section*.39}}
\citation{GuLilGhaTurLev17}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces Critic network graph\relax }}{18}{figure.caption.37}}
\newlabel{fig:criticgraph}{{9}{18}{Critic network graph\relax }{figure.caption.37}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces Actor network graph\relax }}{18}{figure.caption.38}}
\newlabel{fig:actorgraph}{{10}{18}{Actor network graph\relax }{figure.caption.38}{}}
\@writefile{toc}{\contentsline {paragraph}{}{18}{section*.40}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3}Improvement}{18}{subsection.5.3}}
\bibdata{report}
\bibcite{1606.01540}{{1}{2016}{{Brockman et~al.}}{{Brockman, Cheung, Pettersson, Schneider, Schulman, Tang, and Zaremba}}}
\bibcite{GuLilGhaTurLev17}{{2}{2017}{{Gu et~al.}}{{Gu, Lillicrap, Ghahramani, Turner, and Levine}}}
\bibcite{journals/corr/LillicrapHPHETS15}{{3}{2015}{{Lillicrap et~al.}}{{Lillicrap, Hunt, Pritzel, Heess, Erez, Tassa, Silver, and Wierstra}}}
\bibstyle{plainnat}
